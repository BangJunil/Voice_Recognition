{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 264.23 MiB, increment: 0.08 MiB\n"
     ]
    }
   ],
   "source": [
    "% memit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> 보이스데이터->분석용데이터 feature 추출</b></font>\n",
    "- logspec = librosa.amplitude_to_db(melspec) - librosa 함수 수정\n",
    "- fn 파일 경로 구분자 수정\n",
    "- 각 폴더 내 각 레이블 데이터 모두 포함 ( 0 ~ N ) - N = 레이블 수\n",
    "- 현재 N => 여, 남, 소, 남노, 여노 = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://egloos.zum.com/nemonein/v/5326841\n",
    "rename code\n",
    "\n",
    "\n",
    "rename 's/name1/name2/' targetfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*\",bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            fn = fn.replace('\\\\','/')\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "#            print(fn)\n",
    "            label = int(fn.split('/')[3].split('_')[0])\n",
    "        \n",
    "#            print(label)\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                #print(\"-w\", window_size)\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                #print(\"-s\",int(len(sound_clip[start:end])))\n",
    "                if(len(sound_clip[start:end]) == int(window_size)):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                    logspec = librosa.amplitude_to_db(melspec)\n",
    "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                    log_specgrams.append(logspec)\n",
    "                    labels.append(label)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def extract_feature_array(filename, bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    sound_clip,s = librosa.load(filename)        \n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "            logspec = librosa.amplitude_to_db(melspec)\n",
    "            logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "            log_specgrams.append(logspec)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 -> npy 파일 생성\n",
    "- train, valid, test용 audio npy 파일 생성\n",
    "- 훈련용 데이터 셋을 폴더 단위로 저장\n",
    "- 현재 트레이닝 데이터셋은 1개 폴더로 구성\n",
    "- train, valid, test_fold_name 은 사용자 편의에 맞게 명명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_folds(data_dir):\n",
    "    for k in range(0,3):\n",
    "        fold_name = fold_n[k]\n",
    "        print (\"\\nSaving \" + fold_name)\n",
    "        features, labels = extract_features(parent_dir, [fold_name])\n",
    "        labels = one_hot_encode(labels)\n",
    "        \n",
    "        print (\"Features of\", fold_name , \" = \", features.shape)\n",
    "        print (\"Labels of\", fold_name , \" = \", labels.shape)\n",
    "        \n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        np.save(feature_file, features)\n",
    "        print (\"Saved \" + feature_file)\n",
    "        np.save(labels_file, labels)\n",
    "        print (\"Saved \" + labels_file)\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    mydir = os.path.join(os.getcwd(), path)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.makedirs(mydir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npz파일로부터 feature, label 정보 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_folds(): \n",
    "    subsequent_fold = False\n",
    "    for k in range(0,1):\n",
    "        fold_name = 'fold' + str(k)\n",
    "        #fold_name = fold_n[k]\n",
    "        print (\"\\nAdding \" + fold_name)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print (\"New Features: \", loaded_features.shape)\n",
    "\n",
    "        if subsequent_fold:\n",
    "            train_x = np.concatenate((features, loaded_features))\n",
    "            train_y = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            train_x = loaded_features\n",
    "            train_y = loaded_labels\n",
    "            subsequent_fold = True\n",
    "        \n",
    "    valid_fold_name = 'valid'\n",
    "    feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "    valid_x = np.load(feature_file)\n",
    "    valid_y = np.load(labels_file) \n",
    "\n",
    "    # and use the last fold for testing\n",
    "    test_fold_name = 'test'\n",
    "    feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "    test_x = np.load(feature_file)\n",
    "    test_y = np.load(labels_file)\n",
    "    \n",
    "def load_folds(folds):\n",
    "    subsequent_fold = False\n",
    "    for k in range(len(folds)):\n",
    "        #fold_name = 'fold' + str(folds[k])\n",
    "        fold_name = fold_n[folds[k]]\n",
    "        print(fold_name)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print (fold_name, \"features: \", loaded_features.shape)\n",
    "\n",
    "        if subsequent_fold:\n",
    "            features = np.concatenate((features, loaded_features))\n",
    "            labels = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            features = loaded_features\n",
    "            labels = loaded_labels\n",
    "            subsequent_fold = True\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> 특성값 추출 </b></font>\n",
    "- 특정 음성파일 입력 시 data point 및 특성값 결과 추출 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: Initial Data Points = 27099\n",
      "OUT: Total features = (1, 60, 41, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_filename = \"data/Cut_Old_Men/5_oldman000.wav\"\n",
    "features = extract_feature_array(sample_filename)\n",
    "data_points, _ = librosa.load(sample_filename)\n",
    "print (\"IN: Initial Data Points =\", len(data_points))\n",
    "print (\"OUT: Total features =\", np.shape(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> train, valid, test용 audio npy 파일 생성 코드 (박)</b></font>\n",
    "- 위 함수 호출\n",
    "- fold_name 코드 수정 ( 이전, fold_name = 'fold' + str(k) )\n",
    "- urban dataset 상에는 fold + 숫자 형태로 파일 저장\n",
    "- train, valid, test 폴더로 구분하여 특성, 레이블 값 추출\n",
    "- 레이블 : 여 0, 남 1, 어린이 2, 노인_여 3, 노인_남, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_n = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving train\n",
      "Features of train  =  (12480, 60, 41, 2)\n",
      "Labels of train  =  (12480, 5)\n",
      "Saved data/dataset_npy/train_x.npy\n",
      "Saved data/dataset_npy/train_y.npy\n",
      "\n",
      "Saving valid\n",
      "Features of valid  =  (2809, 60, 41, 2)\n",
      "Labels of valid  =  (2809, 5)\n",
      "Saved data/dataset_npy/valid_x.npy\n",
      "Saved data/dataset_npy/valid_y.npy\n",
      "\n",
      "Saving test\n",
      "Features of test  =  (1974, 60, 41, 2)\n",
      "Labels of test  =  (1974, 5)\n",
      "Saved data/dataset_npy/test_x.npy\n",
      "Saved data/dataset_npy/test_y.npy\n"
     ]
    }
   ],
   "source": [
    "# 입력 / 저장 경로 설정 및 데이터 변환 음성 -> .npz\n",
    "parent_dir = \"data/dataset/\"  \n",
    "save_dir = \"data/dataset_npy\"\n",
    "assure_path_exists(save_dir)\n",
    "save_folds(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> 음성 분류용 CNN 모델</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, LSTM, GRU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from keras.utils import np_utils\n",
    "#from keras.layers.extra import TimeDistributedConvolution2D, TimeDistributedMaxPooling2D, TimeDistributedFlatten\n",
    "\n",
    "frames = 41\n",
    "bands = 60\n",
    "feature_size = bands * frames #60x41\n",
    "num_labels = 5\n",
    "num_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = Sequential()   \n",
    "    # input: 60x41 data frames, 2 channels => (60,41,2) tensors\n",
    "\n",
    "    # filters of size 1x1 \n",
    "    f_size = 1\n",
    "\n",
    "    model.add(Convolution2D(48, f_size, strides=f_size, kernel_initializer='normal', padding='same', input_shape=(bands, frames, num_channels)))\n",
    "    model.add(Convolution2D(48, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Convolution2D(96, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Convolution2D(96, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # flatten output into a single dimension \n",
    "    # Keras will do shape inference automatically\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # then a fully connected NN layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # finally, an output layer with one node per class\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # use the Adam optimiser\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    y_pred = y_prob.argmax(axis=-1)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    roc = roc_auc_score(test_y, y_prob)\n",
    "    print (\"ROC:\",  round(roc,3))\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.2f}\".format(accuracy))\n",
    "\n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print (\"F-Score:\", round(f,2))\n",
    "    \n",
    "    return roc, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> 생성한 .npz 파일 로드 Train, Valid, Test 데이터로 구분 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "train features:  (12480, 60, 41, 2)\n",
      "valid\n",
      "valid features:  (2809, 60, 41, 2)\n",
      "test\n",
      "test features:  (1974, 60, 41, 2)\n",
      "Building model...\n",
      "Training model...\n",
      "Train on 12480 samples, validate on 2809 samples\n",
      "Epoch 1/10\n",
      "12480/12480 [==============================] - 37s 3ms/step - loss: 0.8115 - acc: 0.6846 - val_loss: 1.7924 - val_acc: 0.4315\n",
      "Epoch 2/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.5816 - acc: 0.7896 - val_loss: 2.8832 - val_acc: 0.3895\n",
      "Epoch 3/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.5243 - acc: 0.8096 - val_loss: 2.2756 - val_acc: 0.3667\n",
      "Epoch 4/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.4791 - acc: 0.8309 - val_loss: 2.1861 - val_acc: 0.4105\n",
      "Epoch 5/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.4412 - acc: 0.8419 - val_loss: 2.2109 - val_acc: 0.3841\n",
      "Epoch 6/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.4035 - acc: 0.8588 - val_loss: 2.3306 - val_acc: 0.4240\n",
      "Epoch 7/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.3754 - acc: 0.8623 - val_loss: 2.4513 - val_acc: 0.4236\n",
      "Epoch 8/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.3668 - acc: 0.8695 - val_loss: 2.3004 - val_acc: 0.4176\n",
      "Epoch 9/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.3451 - acc: 0.8764 - val_loss: 2.4492 - val_acc: 0.4041\n",
      "Epoch 10/10\n",
      "12480/12480 [==============================] - 36s 3ms/step - loss: 0.3316 - acc: 0.8814 - val_loss: 2.9228 - val_acc: 0.4172\n",
      "Evaluating model...\n",
      "ROC: 0.952\n",
      "1974/1974 [==============================] - 1s 528us/step\n",
      "\n",
      "Accuracy = 0.79\n",
      "F-Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/dataset_npy/\"\n",
    "\n",
    "train_x, train_y = load_folds([0])\n",
    "\n",
    "valid_x, valid_y = load_folds([1])\n",
    "    \n",
    "test_x, test_y = load_folds([2])\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(train_x, train_y, validation_data=(valid_x, valid_y),  batch_size=20, epochs=10)\n",
    "# validation에 트레이닝 시 10개 클래스를 했으면 validataion 및 test 데이터에도 10개 클래스 데이터가 있어야 함\n",
    "#model.fit(train_x, train_y, callbacks=[earlystop], batch_size=20, epochs=10)\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "roc, acc = evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=4><b> 음성 예측 (남-여)</b></font>\n",
    "- 현재 데이터는 남자 여자로만 레이블링\n",
    "- 데이터 확보 후 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "parent_dir = 'samples/voice/'\n",
    "sound_file_paths = [\"man_1.mp3\",\"man_2.mp3\",\"man_3.mp3\",\"man_4.mp3\",\"man_5k.mp3\", \"man_6k.mp3\", \"man_7k.mp3\", \"man_8.mp3\",\n",
    "                    \"woman_1.mp3\",\"woman_2.mp3\",\"woman_3k.mp3\",\"woman_4k.mp3\",\"woman_5.mp3\", \"woman_6k.mp3\",\"2_child_177.flac\",\n",
    "                    \"2_child_206.flac\",\"2_child_210.flac\",\"3_oldwoman_211.flac\",\"3_oldwoman_295.flac\",\"3_oldwoman_302.flac\",\n",
    "                    \"4_oldman245.flac\",\"4_oldman249.flac\",\"4_oldman250.flac\",\"4_oldman279.flac\"]\n",
    "\n",
    "#ipd.Audio(parent_dir+sound_file_paths[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----  남성1 -----\n",
      "samples/voice/man_1.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.992 )\n",
      "2순위 예측 (점수):  여성  ( 0.008 )\n",
      "\n",
      "-----  남성2 -----\n",
      "samples/voice/man_2.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.999 )\n",
      "2순위 예측 (점수):  여성  ( 0.001 )\n",
      "\n",
      "-----  남성3 -----\n",
      "samples/voice/man_3.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.876 )\n",
      "2순위 예측 (점수):  여성  ( 0.12 )\n",
      "\n",
      "-----  남성4 -----\n",
      "samples/voice/man_4.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.506 )\n",
      "2순위 예측 (점수):  여성  ( 0.279 )\n",
      "\n",
      "-----  남성5 -----\n",
      "samples/voice/man_5k.mp3\n",
      "1순위 예측 (점수):  어린이  ( 0.798 )\n",
      "2순위 예측 (점수):  남성  ( 0.176 )\n",
      "\n",
      "-----  남성6 -----\n",
      "samples/voice/man_6k.mp3\n",
      "1순위 예측 (점수):  어린이  ( 0.424 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.36 )\n",
      "\n",
      "-----  남성7 -----\n",
      "samples/voice/man_7k.mp3\n",
      "1순위 예측 (점수):  어린이  ( 0.911 )\n",
      "2순위 예측 (점수):  남성  ( 0.044 )\n",
      "\n",
      "-----  남성8 -----\n",
      "samples/voice/man_8.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.909 )\n",
      "2순위 예측 (점수):  여성  ( 0.088 )\n",
      "\n",
      "-----  여성1 -----\n",
      "samples/voice/woman_1.mp3\n",
      "1순위 예측 (점수):  여성  ( 0.954 )\n",
      "2순위 예측 (점수):  어린이  ( 0.025 )\n",
      "\n",
      "-----  여성2 -----\n",
      "samples/voice/woman_2.mp3\n",
      "1순위 예측 (점수):  남성  ( 0.858 )\n",
      "2순위 예측 (점수):  여성  ( 0.136 )\n",
      "\n",
      "-----  여성3 -----\n",
      "samples/voice/woman_3k.mp3\n",
      "1순위 예측 (점수):  노_여성  ( 0.429 )\n",
      "2순위 예측 (점수):  노_남성  ( 0.419 )\n",
      "\n",
      "-----  여성4 -----\n",
      "samples/voice/woman_4k.mp3\n",
      "1순위 예측 (점수):  어린이  ( 0.986 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.01 )\n",
      "\n",
      "-----  여성5 -----\n",
      "samples/voice/woman_5.mp3\n",
      "1순위 예측 (점수):  어린이  ( 0.9 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.085 )\n",
      "\n",
      "-----  여성6 -----\n",
      "samples/voice/woman_6k.mp3\n",
      "1순위 예측 (점수):  여성  ( 0.994 )\n",
      "2순위 예측 (점수):  남성  ( 0.004 )\n",
      "\n",
      "-----  어린이1 -----\n",
      "samples/voice/2_child_177.flac\n",
      "1순위 예측 (점수):  어린이  ( 0.969 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.031 )\n",
      "\n",
      "-----  어린이2 -----\n",
      "samples/voice/2_child_206.flac\n",
      "1순위 예측 (점수):  어린이  ( 1.0 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.0 )\n",
      "\n",
      "-----  어린이3 -----\n",
      "samples/voice/2_child_210.flac\n",
      "1순위 예측 (점수):  어린이  ( 0.977 )\n",
      "2순위 예측 (점수):  노_여성  ( 0.023 )\n",
      "\n",
      "-----  노_여성1 -----\n",
      "samples/voice/3_oldwoman_211.flac\n",
      "1순위 예측 (점수):  노_여성  ( 0.857 )\n",
      "2순위 예측 (점수):  어린이  ( 0.088 )\n",
      "\n",
      "-----  노_여성2 -----\n",
      "samples/voice/3_oldwoman_295.flac\n",
      "1순위 예측 (점수):  노_여성  ( 0.719 )\n",
      "2순위 예측 (점수):  어린이  ( 0.235 )\n",
      "\n",
      "-----  노_여성3 -----\n",
      "samples/voice/3_oldwoman_302.flac\n",
      "1순위 예측 (점수):  노_여성  ( 0.9 )\n",
      "2순위 예측 (점수):  어린이  ( 0.061 )\n",
      "\n",
      "-----  노_남성1 -----\n",
      "samples/voice/4_oldman245.flac\n",
      "1순위 예측 (점수):  남성  ( 0.398 )\n",
      "2순위 예측 (점수):  노_남성  ( 0.229 )\n",
      "\n",
      "-----  노_남성2 -----\n",
      "samples/voice/4_oldman249.flac\n",
      "1순위 예측 (점수):  노_여성  ( 0.374 )\n",
      "2순위 예측 (점수):  노_남성  ( 0.26 )\n",
      "\n",
      "-----  노_남성3 -----\n",
      "samples/voice/4_oldman250.flac\n",
      "1순위 예측 (점수):  노_남성  ( 0.419 )\n",
      "2순위 예측 (점수):  여성  ( 0.336 )\n",
      "\n",
      "-----  노_남성4 -----\n",
      "samples/voice/4_oldman279.flac\n",
      "1순위 예측 (점수):  노_여성  ( 0.389 )\n",
      "2순위 예측 (점수):  여성  ( 0.255 )\n"
     ]
    }
   ],
   "source": [
    "sound_names = [\"남성1\",\"남성2\",\"남성3\",\"남성4\",\"남성5\", \"남성6\", \"남성7\", \"남성8\",\n",
    "               \"여성1\",\"여성2\",\"여성3\",\"여성4\",\"여성5\", \"여성6\",\"어린이1\",\"어린이2\",\"어린이3\",\n",
    "               \"노_여성1\",\"노_여성2\",\"노_여성3\",\"노_남성1\",\"노_남성2\",\"노_남성3\",\"노_남성4\"]\n",
    "\n",
    "rst_value = [\"여성\", \"남성\", \"어린이\",\"노_여성\",\"노_남성\"]\n",
    "\n",
    "\n",
    "for s in range(len(sound_names)):\n",
    "\n",
    "    print (\"\\n----- \", sound_names[s], \"-----\")\n",
    "    \n",
    "    predict_file = parent_dir + sound_file_paths[s]\n",
    "    predict_x = extract_feature_array(predict_file)\n",
    "    print(predict_file)\n",
    "    predictions = model.predict(predict_x)\n",
    "    \n",
    "    if len(predictions) == 0: \n",
    "        print (\"No prediction\")\n",
    "        continue\n",
    "    \n",
    "    #for i in range(len(predictions[0])):\n",
    "    #    print (sound_names[i], \"=\", round(predictions[0,i] * 100, 1))\n",
    "    #print(predictions)\n",
    "    \n",
    "    ind = np.argpartition(predictions[0], -2)[-2:] # 큰값 상위 2개의 index\n",
    "    #print(predictions)\n",
    "    ind[np.argsort(predictions[0][ind])]\n",
    "    ind = ind[::-1]\n",
    "    #print(ind)\n",
    "    \n",
    "    print (\"1순위 예측 (점수): \", rst_value[ind[0]], \" (\",round(predictions[0,ind[0]],3),\")\")\n",
    "    print (\"2순위 예측 (점수): \", rst_value[ind[1]], \" (\",round(predictions[0,ind[1]],3),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_2epoch_CNN_2Dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
